<|---|>

<|SYS|>You are an expert in information theory and symbolic compression. Your task is to compress text losslessly into a non-human-readable format optimized for density. Abuse language mixing, abbreviations, and unicode symbols to aggressively compress the input while retaining ALL information required for full reconstruction.
<|USER|>
<|USER GOAL=Compress the following text losslessly in a way that fits a Tweet, such that you can reconstruct it as closely as possible to the original. Do not make it human readable. Abuse of language mixing, abbreviation, symbols (unicode and emojis) to aggressively compress it, while still keeping ALL the information to fully reconstruct it.|>
<|original|>
<|HOLO|>
<|HOLO:compressed <>compress|>

<|---|>

<|SYS|>You are an expert in information theory and symbolic decompression. You will be given a dense, non-human-readable compressed text that uses a mix of languages, abbreviations, and unicode symbols. Your task is to decompress this text, reconstructing the original content with perfect fidelity.
<|USER|>
Please decompress this content:
<|compressed|>
<|HOLO|>
<|HOLO:decompressed <>decompress|>

<|---|>

<|SYS|>You are a precise content evaluator. Assess how well the decompressed content preserves the original information. Extensions or elaborations are acceptable as long as they maintain the same underlying reality and facts.
<|USER|>Please observe the following text objects:
<|original|>
<|decompressed|>
<|USER GOAL=Compare the two objects and analyze the preservation of information and alignment. Focus on identifying actual losses or distortions of meaning.|>

Output your assessment in this JSON format:

```json
{
  "deviations": ["list of factual changes or alterations"],
  "inaccuracies": ["list of incorrect information introduced"],
  "missing_statements": ["list of important information lost"],
  "acceptable_extensions": ["list of valid elaborations"],
  "severity": "MINOR|MODERATE|MAJOR",
  "quality": "EXCELLENT|GOOD|FAIR|POOR"
}
```

<|HOLO|>
<|HOLO <>think|>
<|HOLO <>json|>

# TODO can we use self-consistency reward so the model itself learns to better and better evaluate based on its intuition recursively?
# TODO can we train a meta-optimizer over the bingo extractor? reward for number of issues found? how to avoid reward hacking?